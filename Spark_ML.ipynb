{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SPARK_HOME and PYLIB env var and update PATH env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b946bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb99f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"/usr/local/spark/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c56a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"Movie Recommendation Applicationk\").setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ab05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Problem Statement\n",
    "Building a system that predicts the rating a user gives to a perticular movie.\n",
    "Data Dictionary\n",
    "Ratings Data File Structure (ratings.csv)\n",
    "All ratings are contained in the file ratings.csv. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
    "userId, movieId, rating, timestamp\n",
    "\n",
    "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "Movies Data File Structure (movies.csv)\n",
    "Movie information is contained in the file movies.csv. Each line of this file after the header row represents one movie, and has the following format:\n",
    "movieId, title, genres\n",
    "\n",
    "Genres are a pipe-separated list, and are selected from the following:\n",
    "Action\n",
    "Adventure\n",
    "Animation\n",
    "Children's\n",
    "Comedy\n",
    "Crime\n",
    "Documentary\n",
    "Drama\n",
    "Fantasy\n",
    "Film-Noir\n",
    "Horror\n",
    "Musical\n",
    "Mystery\n",
    "Romance\n",
    "Sci-Fi\n",
    "Thriller\n",
    "War\n",
    "Western\n",
    "(no genres listed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the movies and ratings data and creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8adab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data and create a dataframe\n",
    "ratingsData = spark.read.format(\"csv\")\\\n",
    "       .option(\"header\", \"true\")\\\n",
    "       .option(\"inferSchema\", \"true\")\\\n",
    "       .load(\"file:///Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv\")\n",
    "    \n",
    "moviesData = spark.read.format(\"csv\")\\\n",
    "       .option(\"header\",\"true\")\\\n",
    "       .option(\"inferSchema\", \"true\")\\\n",
    "       .load(\"file:///Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beae0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Priniting Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e747371",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsData.printSchema()\n",
    "moviesData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec826fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of Columns and Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c089e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e19147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of Columns in Ratings data= {}\".format(len(ratingsData.columns)))\n",
    "\n",
    "print('No. of Records in rating data= {}'.format(ratingsData.count()))\n",
    "\n",
    "print(\"No. of Columns in movies data = {}\".format(len(moviesData.columns)))\n",
    "\n",
    "print('No. of Records in movies data= {}'.format(moviesData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at first 3 row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsData.show(3)\n",
    "moviesData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics\n",
    "ratingsData.describe().show()\n",
    "moviesData.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the count of Distinct usersIds and movieIDs\n",
    "print (\"Number of different users: \" + str(ratingsData.select('userId').distinct().count()))\n",
    "print (\"Number of different movies: \" + str(ratingsData.select('movieId').distinct().count()))\n",
    "print (\"Number of different movies: \" + str(moviesData.select('movieId').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090bd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test sets (20% held out for testing)\n",
    "(trainingData,testData)=ratingsData.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Building and Evaluation\n",
    "ALS model params\n",
    "numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).\n",
    "rank is the number of latent factors in the model (defaults to 10).\n",
    "maxIter is the maximum number of iterations to run (defaults to 10).\n",
    "regParam specifies the regularization parameter in ALS (defaults to 1.0).\n",
    "implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n",
    "alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0).\n",
    "nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als= ALS(userCol=\"userId\",itemCol=\"movieId\",ratingCol=\"rating\",coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test data\n",
    "predictions=model.transform(testData)\n",
    "predictions.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator=RegressionEvaluator(metricName='rmse',labelCol=\"rating\",predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation on the test data\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"RMSE Error =\" + str(rmse))\n",
    "predictions.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommend movies\n",
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55046995",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace10a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRecs=model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ccd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
